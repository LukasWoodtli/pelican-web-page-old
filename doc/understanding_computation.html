<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="author" content="Lukas Woodtli" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="Computer Science, Programming, " />

<meta property="og:title" content="Understanding Computation "/>
<meta property="og:url" content="./understanding_computation.html" />
<meta property="og:description" content="This page collects notes and citations from the book: Understanding Computation by Tom Stuart I. Programs and Machines “To create an environment where […] computation can occur, we need three basic ingredients:” “A machine capable of performing the computation” “A language for writing instructions that the machine can understand” “A program …" />
<meta property="og:site_name" content="Lukas Woodtli" />
<meta property="og:article:author" content="Lukas Woodtli" />
<meta property="og:article:published_time" content="2016-09-12T21:50:33+02:00" />
<meta property="og:article:modified_time" content="2022-04-10T22:19:46+02:00" />
<meta name="twitter:title" content="Understanding Computation ">
<meta name="twitter:description" content="This page collects notes and citations from the book: Understanding Computation by Tom Stuart I. Programs and Machines “To create an environment where […] computation can occur, we need three basic ingredients:” “A machine capable of performing the computation” “A language for writing instructions that the machine can understand” “A program …">

        <title>Understanding Computation  · Lukas Woodtli
</title>
        <link href="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/css/bootstrap-combined.min.css" rel="stylesheet">
        <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.1/css/font-awesome.css" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="./theme/css/pygments.css" media="screen">
        <link rel="stylesheet" type="text/css" href="./theme/tipuesearch/tipuesearch.css" media="screen">
        <link rel="stylesheet" type="text/css" href="./theme/css/elegant.css" media="screen">
        <link rel="stylesheet" type="text/css" href="./theme/css/admonition.css" media="screen">
        <link rel="stylesheet" type="text/css" href="./theme/css/custom.css" media="screen">



    </head>
    <body>
        <div id="content-sans-footer">
        <div class="navbar navbar-static-top">
            <div class="navbar-inner">
                <div class="container-fluid">
                    <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </a>
                    <a class="brand" href="./"><span class=site-name>Lukas Woodtli</span></a>
                    <div class="nav-collapse collapse">
                        <ul class="nav pull-right top-menu">
                            <li ><a href=".">Home</a></li>
                            <li><a href="./pages/resume.html">Resume</a></li>
                            <li><a href="./pages/skills.html">Skills</a></li>
                            <li><a href="./pages/books.html">Books</a></li>
                            <li><a href="./pages/courses.html">Courses</a></li>
                            <li><a href="./pages/projects.html">Projects</a></li>
                            <li><a href="./pages/blog.html">Blog</a></li>
                            <li><a href="./pages/contact.html">Contact</a></li>
                            <!-- <li ><a href="./categories">Categories</a></li> -->
                            <!-- <li ><a href="./tags">Tags</a></li> -->
                            <!-- <li ><a href="./archives">Archives</a></li> -->

                            <li><form class="navbar-search" action="./search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        <div class="container-fluid">
            <div class="row-fluid">
                <div class="span1"></div>
                <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
    <h1><a href="./understanding_computation.html"> Understanding&nbsp;Computation  </a></h1>
    </header>
</div>

<div class="row-fluid">
    <div class="span2 table-of-content">
        <nav>
        <h4>Contents</h4>
        <div class="toc">
<ul>
<li><a href="#i-programs-and-machines">I. Programs and Machines</a><ul>
<li><a href="#the-meaning-of-programs">The Meaning of Programs</a><ul>
<li><a href="#the-meaning-of-meaning">The Meaning of “Meaning”</a></li>
<li><a href="#operational-semantics">Operational Semantics</a></li>
</ul>
</li>
<li><a href="#the-simplest-computers">The Simplest Computers</a></li>
<li><a href="#just-add-power">Just Add Power</a></li>
<li><a href="#the-ultimate-machine">The Ultimate Machine</a></li>
</ul>
</li>
<li><a href="#ii-computation-and-computability"><span class="caps">II</span>. Computation and Computability</a><ul>
<li><a href="#programming-with-nothing">Programming with Nothing</a></li>
<li><a href="#universality-is-everywhere">Universality Is Everywhere</a><ul>
<li><a href="#partial-recursive-functions">Partial Recursive Functions</a></li>
<li><a href="#ski-combinator-calculus"><span class="caps">SKI</span> Combinator Calculus</a></li>
<li><a href="#iota">Iota</a></li>
<li><a href="#tag-systems">Tag Systems</a></li>
</ul>
</li>
<li><a href="#impossible-programs">Impossible Programs</a><ul>
<li><a href="#code-is-data">Code Is Data</a></li>
<li><a href="#universal-systems-can-loop-forever">Universal Systems Can Loop Forever</a></li>
<li><a href="#decidability">Decidability</a></li>
<li><a href="#the-halting-problem">The Halting Problem</a></li>
</ul>
</li>
<li><a href="#programming-in-toyland">Programming in Toyland</a><ul>
<li><a href="#abstract-interpretation">Abstract Interpretation</a></li>
<li><a href="#static-semantics">Static Semantics</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#afterword">Afterword</a></li>
</ul>
</div>
        </nav>
    </div>
    <div class="span8 article-content">

            
            <p>This page collects notes and citations from the book:</p>
<p><a href="http://computationbook.com/">Understanding Computation by Tom Stuart</a></p>

<h1 id="i-programs-and-machines">I. Programs and Machines</h1>
<p><em><span class="dquo">“</span>To create an environment where […] computation can occur, we need three basic ingredients:”</em></p>
<ul>
<li><em><span class="dquo">“</span>A </em><em>machine</em><em> capable of performing the computation”</em></li>
<li><em><span class="dquo">“</span>A </em><em>language</em><em> for writing instructions that the machine can understand”</em></li>
<li><em><span class="dquo">“</span>A </em><em>program</em><em> written in that language, describing the exact computation that the machine should perform”</em> - page 18</li>
</ul>
<h2 id="the-meaning-of-programs">The Meaning of Programs</h2>
<p><em><span class="dquo">“</span>But computer programming isn’t really about </em><em>programs</em><em>, it’s about </em><em>ideas</em><em>”</em> - page 20</p>
<h3 id="the-meaning-of-meaning">The Meaning of “Meaning”</h3>
<p><em><span class="dquo">“</span>semantics is the study of the connection between words and their meanings”</em> - page 21</p>
<h3 id="operational-semantics">Operational Semantics</h3>
<p>Expression and Statements:</p>
<p><em><span class="dquo">“</span>The purpose of an expression is to be evaluated to produce another expression; a statement, on the other hand, is evaluated to make some change to the state of the abstract machine.”</em> - page 35</p>
<p><em><span class="dquo">“</span>difference between expressions and statements. For expressions, we pass an environment into #reduce and get a reduced expression back; no new environment is returned”</em> - page 37</p>
<p><em><span class="dquo">“</span>[<span class="caps">SIMPLE</span>’s] expressions are pure and its statements are impure”</em> - page 37</p>
<p><em><span class="dquo">“</span>conditional statements like <code>« if (x) { y = 1 } else { y = 2 } »</code>, which contain an expression called the condition (<code>« x »</code>), and two statements that we’ll call the consequence (<code>« y = 1 »</code>) and the alternative (<code>« y = 2 »</code>)”</em> - page 39</p>
<p><em><span class="dquo">“</span>the latest <span class="caps">R6RS</span> standard for the Scheme programming language uses small-step semantics to describe its execution”</em> - page 45</p>
<p><em><span class="dquo">“</span>small-step semantics has a mostly iterative flavor, requiring the abstract machine to repeatedly perform reduction steps”</em> - page 45</p>
<p><em><span class="dquo">“</span>[Big-step semantics:] recursive rather than an iterative process”</em> - page 46</p>
<ul>
<li>Small-step semantics: iterative</li>
<li>Big-step semantics: recursive</li>
</ul>
<p><em><span class="dquo">“</span>operational semantics is about explaining a language’s meaning by designing an interpreter for it. By contrast, the language-to-language translation of denotational semantics is like a compiler”</em> - page 60</p>
<p><em><span class="dquo">“</span>[It’s] possible to compare two programs written in different languages, if a denotational semantics exists to translate both languages into some shared representation”</em> - page 62</p>
<p><em><span class="dquo">“</span>Small-step semantics is also known as structural operational semantics and transition semantics”</em> - page 63</p>
<p><em><span class="dquo">“</span>big-step semantics is more often called natural semantics or relational semantics”</em> - page 63</p>
<p><em><span class="dquo">“</span>denotational semantics is also called fixed-point semantics or mathematical semantics”</em> - page 63</p>
<p><em><span class="dquo">“</span>One alternative is axiomatic semantics”</em> - page 64</p>
<ul>
<li>Design by Contract (pre-/post-conditions)</li>
</ul>
<p><em><span class="dquo">“</span>Reducing an expression and an environment gives us a new expression, and we may reuse the old environment next time; reducing a statement and an environment gives us a new statement and a new environment.”</em> - page 70</p>
<p><em><span class="dquo">“</span>alternative style of operational semantics, called reduction semantics , which explicitly separates these “what do we reduce next?” and “how do we reduce it?” phases by introducing so-called reduction contexts”</em> - page 71</p>
<h2 id="the-simplest-computers">The Simplest Computers</h2>
<p><em><span class="dquo">“</span>each finite automaton has a hardcoded collection of rules that determine how it should move from one state to another in response to input”</em> - page 73</p>
<p><em><span class="dquo">“</span>finite automata also have a rudimentary way of producing output”</em> - page 74</p>
<p><em><span class="dquo">“</span>[Deterministic finite automaton:] it’s always absolutely certain which state it will end up in”</em> - page 75</p>
<p><em><span class="dquo">“</span>a string is accepted if there’s some way for the </em><em><span class="caps">NFA</span></em><em> to end up in an accept state by following some of its rules—that is, if finishing in an accept state is possible , even if it’s not inevitable.”</em> - page 81</p>
<p><em><span class="dquo">“</span>The collection of strings that are accepted by a particular machine is called a language : we say that the machine recognizes that language.”</em> - page 82</p>
<p><em><span class="dquo">“</span>those languages that can be recognized by finite automata are called regular languages”</em> - page 82</p>
<p><em><span class="dquo">“</span>[…] introducing another machine feature called free moves. These are rules that the machine may spontaneously follow without reading any input”</em> - page 88</p>
<p><em><span class="dquo">“</span>The characters read by finite automata are usually called </em><em>symbols</em><em>, the rules for moving between states are called </em><em>transitions</em><em>, and the collection of rules making up a machine is called a </em><em>transition function</em><em> (or sometimes transition relation for NFAs)”</em> - page 91</p>
<p><em><span class="dquo">“</span><span class="caps">NFA</span> with free moves is known as an <span class="caps">NFA</span>-ε, and free moves themselves are usually called ε-transitions.”</em> - page 91</p>
<p><em><span class="dquo">“</span>it’s possible to convert any regular expression into an equivalent <span class="caps">NFA</span>—every string matched by the regular expression is accepted by the <span class="caps">NFA</span>, and vice versa — and then match a string by feeding it to a simulation of that <span class="caps">NFA</span> to see whether it gets accepted.”</em> - page 92</p>
<p><em><span class="dquo">“</span>here are two kinds of extremely simple regular expression that are not built out of anything simpler:</em></p>
<ul>
<li><em>An empty regular expression. This matches the empty string and nothing else.</em></li>
<li><em>A regular expression containing a single, literal character. For example, <code>a</code> and <code>b</code> are regular expressions that match only the strings ‘<code>a</code><span class="quo">‘</span> and ‘<code>b</code><span class="quo">‘</span> respectively.”</em> - page 92</li>
</ul>
<p><em><span class="dquo">“</span>combine them to build more complex expressions:</em></p>
<ul>
<li><em>Concatenate two patterns. We can concatenate the regular expressions <code>a</code> and <code>b</code> to get the regular expression <code>ab</code> , which only matches the string ‘<code>ab</code><span class="quo">‘</span>.</em></li>
<li><em>Choose between two patterns, written by joining them with the <code>|</code> operator. We can join the regular expressions <code>a</code> or <code>b</code> to get the regular expression <code>a|b</code> , which matches the strings ‘<code>a</code><span class="quo">‘</span> and ‘<code>b</code><span class="quo">‘</span>.</em></li>
<li><em>Repeat a pattern zero or more times, written by suffixing it with the <code>*</code> operator. We can suffix the regular expression a to get <code>a*</code> , which matches the strings ‘<code>a</code><span class="quo">‘</span> , ‘<code>aa</code><span class="quo">‘</span> , ‘<code>aaa</code><span class="quo">‘</span> , and so on, as well as the empty string ” (i.e., zero repetitions).”</em> - page 92</li>
</ul>
<p><em><span class="dquo">“</span>the <code>*</code> operator to bind more tightly than </em><em>concatenation</em><em>, which in turn binds more tightly than the <code>|</code> operator.”</em> - page 94</p>
<p><em><span class="dquo">“</span>Any two NFAs can be concatenated by turning every accept state from the first <span class="caps">NFA</span> into a nonaccept state and connecting it to the start state of the second <span class="caps">NFA</span> with a free move”</em> - page 97</p>
<ul>
<li><em><span class="dquo">“</span>The start state of the first <span class="caps">NFA</span>”</em></li>
<li><em><span class="dquo">“</span>The accept states of the second <span class="caps">NFA</span>”</em></li>
<li><em><span class="dquo">“</span>All the rules from both NFAs”</em></li>
<li><em><span class="dquo">“</span>Some extra free moves to connect each of the first <span class="caps">NFA</span>’s old accept states to the second <span class="caps">NFA</span>’s old start state”</em> - page 98</li>
</ul>
<p><em><span class="dquo">“</span>We can use a similar strategy to convert a</em> <code>Choose</code> <em>expression into an <span class="caps">NFA</span>.”</em> - page 98</p>
<ul>
<li><em><span class="dquo">“</span>A new start state”</em></li>
<li><em><span class="dquo">“</span>All the accept states from both NFAs”</em></li>
<li><em><span class="dquo">“</span>All the rules from both NFAs”</em></li>
<li><em><span class="dquo">“</span>Two extra free moves to connect the new start state to each of the <span class="caps">NFA</span>’s old start states”</em> - page 100</li>
</ul>
<p><em><span class="dquo">“</span>We can do the same for any <span class="caps">NFA</span> […]. This time we need:</em></p>
<ul>
<li><em>A new start state, which is also an accept state</em></li>
<li><em>All the accept states from the old <span class="caps">NFA</span></em></li>
<li><em>All the rules from the old <span class="caps">NFA</span></em></li>
<li><em>Some extra free moves to connect each of the old <span class="caps">NFA</span>’s accept states to its old start state</em></li>
<li><em>Another extra free move to connect the new start state to the old start state</em> - page 101</li>
</ul>
<p><em><span class="dquo">“</span>Free moves are useful for this conversion because they provide an unobtrusive way to glue together smaller machines into larger ones without affecting the behavior of any of the components.”</em> - page 102</p>
<p><em><span class="dquo">“</span>Nondeterminism and free moves make it easier to design finite state machines to perform specific jobs”</em> - page 105</p>
<p><em><span class="dquo">“</span>it’s possible to convert any nondeterministic finite automaton into a deterministic one that accepts exactly the same strings”</em> - page 105</p>
<h2 id="just-add-power">Just Add Power</h2>
<p><em><span class="dquo">“</span>A finite state machine with a built-in stack is called a pushdown automaton (<span class="caps">PDA</span>), and when that machine’s rules are deterministic, we call it a deterministic pushdown automaton (<span class="caps">DPDA</span>).”</em> - page 122</p>
<p><em><span class="dquo">“</span>[…] a <span class="caps">PDA</span> rule into five parts:</em></p>
<ul>
<li><em>The current state of the machine</em></li>
<li><em>The character that must be read from the input (optional)</em></li>
<li><em>The next state of the machine</em></li>
<li><em>The character that must be popped off the stack</em></li>
<li><em>The sequence of characters to push onto the stack after the top character has been popped off”</em></li>
</ul>
<p>page 123</p>
<p><em><span class="dquo">“</span>The assumption is that a <span class="caps">PDA</span> will always pop the top character off the stack, and then push some other characters onto the stack, every time it follows a rule. Each rule declares which character it wants to pop, and the rule will only apply when that character is on the top of the stack; if the rule wants that character to stay on the stack instead of getting popped, it can include it in the sequence of characters that get pushed back on afterward.”</em> - page 123</p>
<p><em><span class="dquo">“</span>[…] mark the bottom of the stack—the dollar sign,</em> <code>$</code>, <em>is a popular choice”</em> - page 124</p>
<p><em><span class="dquo">“</span>there are two important things to know about a pushdown automaton at each step of its computation: what its current state is, and what the current contents of its stack are. If we use the word </em><em>configuration</em><em> to refer to this combination of a state and a stack, we can talk about a pushdown automaton moving from one configuration to another as it reads input characters”</em> - page 126</p>
<p><em><span class="dquo">“</span>there isn’t an <span class="caps">NPDA</span>-to-<span class="caps">DPDA</span> algorithm.”</em> - page 139</p>
<p><em><span class="dquo">“</span>Lexical analysis</em></p>
<p><em>Read a raw string of characters and turn it into a sequence of tokens. Each token represents an individual building block of program syntax, like “variable name,” “opening bracket,” or ” while keyword.” A lexical analyzer uses a language-specific set of rules called a lexical grammar to decide which sequences of characters should produce which tokens. This stage deals with messy character-level details like variable-naming rules, comments, and whitespace, leaving a clean sequence of tokens for the next stage to consume.”</em> - page 139</p>
<p><em><span class="dquo">“</span>Syntactic analysis</em></p>
<p><em>Read a sequence of tokens and decide whether they represent a valid program according to the syntactic grammar of the language being parsed. If the program is valid, the syntactic analyzer may produce additional information about its structure (e.g., a parse tree).”</em> - page 140</p>
<p><em><span class="dquo">“</span>context-free grammar (<span class="caps">CFG</span>)</em></p>
<p><em>Each rule has a symbol on the lefthand side and one or more sequences of symbols and tokens on the right”</em> - page 143</p>
<p><em><span class="dquo">“</span>The technique for converting a <span class="caps">CFG</span> into a <span class="caps">PDA</span> works like this:</em></p>
<ol>
<li><em>Pick a character to represent each symbol from the grammar</em></li>
<li><em>Use the <span class="caps">PDA</span>’s stack to store characters that represent grammar symbols and tokens. When the <span class="caps">PDA</span> starts, have it immediately push a symbol onto the stack to represent the structure it’s trying to recognize.</em></li>
<li><em>Translate the grammar rules into <span class="caps">PDA</span> rules that expand symbols on the top of the stack without reading any input. Each grammar rule describes how to expand a single symbol into a sequence of other symbols and tokens</em></li>
<li><em>Give every token character a <span class="caps">PDA</span> rule that reads that character from the input and pops it off the stack</em></li>
</ol>
<p><em>These token rules work in opposition to the symbol rules. The symbol rules tend to make the stack larger, sometimes pushing several characters to replace the one that’s been popped; the token rules always make the stack smaller, consuming input as they go.</em></p>
<p>5. <em>Finally, make a <span class="caps">PDA</span> rule that will allow the machine to enter an accept state if the stack becomes empty</em> - pages 143-145</p>
<p><em><span class="dquo">“</span>the symbol rules repeatedly expand the symbol on the top of the stack until it gets replaced by a token, then the token rules consume the stack (and the input) until they hit a symbol. This back and forth eventually results in an empty stack as long as the input string can be generated by the grammar rules.”</em></p>
<p><em><span class="dquo">“</span>This algorithm is called </em><em><span class="caps">LL</span></em><em> parsing. The first L stands for “left-to-right,” because the input string is read in that direction, and the second L stands for “left derivation,” because it’s always the leftmost (i.e., uppermost) symbol on the stack that gets expanded.”</em> - page 146</p>
<p><em><span class="dquo">“</span>The unlimited storage provided by a stack lets a <span class="caps">PDA</span> remember arbitrary amounts of information during a computation and refer back to it later.”</em> - page 148</p>
<p><em><span class="dquo">“</span>There’s a feedback loop between the rules and the stack—the contents of the stack affect which rules the machine can follow, and following a rule will affect the stack contents—which allows a <span class="caps">PDA</span> to store away information on the stack that will influence its future execution.”</em> - page 148</p>
<h2 id="the-ultimate-machine">The Ultimate Machine</h2>
<p>Turing machine:</p>
<p><em><span class="dquo">“</span>[…] unified rule format has five parts:</em></p>
<ul>
<li><em>The current state of the machine</em></li>
<li><em>The character that must appear at the tape head’s current position</em></li>
<li><em>The next state of the machine</em></li>
<li><em>The character to write at the tape head’s current position</em></li>
<li><em>The direction (left or right) in which to move the head after writing to the tape”</em> - page 156</li>
</ul>
<p><em><span class="dquo">“</span>we don’t have to worry about free moves, because Turing machines don’t have them.”</em> - pages 160</p>
<p><em><span class="dquo">“</span>A Turing machine’s next action is chosen according to its current state and the character currently underneath its tape head, so a deterministic machine can only have one rule for each combination of state and character—the “no contradictions” rule—in order to prevent any ambiguity over what its next action will be.”</em> - page 160</p>
<p><em><span class="dquo">“</span>there’s an implicit stuck state that the machine can go into when no rule applies</em>” - page 160</p>
<p><em><span class="dquo">“</span>does adding nondeterminism make a Turing machine more powerful? In this case the answer is no: a nondeterministic Turing machine can’t do any more than a deterministic one. Pushdown automata are the exception here, because both DFAs and DTMs have enough power to simulate their nondeterministic counterparts. A single state of a finite automaton can be used to represent a combination of many states, and a single Turing machine tape can be used to store the contents of many tapes, but a single pushdown automaton stack can’t represent many possible stacks at once.”</em> - page 166</p>
<p><em><span class="dquo">“</span>can we design a single machine that can read a program from its input and then do whatever job the program specifies? Perhaps unsurprisingly, a Turing machine is powerful enough to read the description of a simple machine from its tape - a deterministic finite automaton, say - and then run a simulation of that machine to find out what it does.”</em> - page 176</p>
<p><em><span class="dquo">“</span>we are able to design a machine that can simulate any other <span class="caps">DTM</span> by reading its rules, accept states, and initial configuration from the tape and stepping through its execution, essentially acting as a Turing machine rulebook interpreter. A machine that does this is called a </em><em>universal Turing machine</em><em> (<span class="caps">UTM</span>).”</em> - page 177</p>
<p><em><span class="dquo">“</span>We can write software - an encoded description of a Turing machine - onto a tape, feed that tape to the <span class="caps">UTM</span>, and have our software executed to produce the behavior we want.”</em> - page 177</p>
<p><em><span class="dquo">“</span>One challenge is that every Turing machine has a finite number of states and a finite number of different characters it can store on its tape, with both of these numbers being fixed in advance by its rulebook, and a <span class="caps">UTM</span> is no exception.</em>” - page 178</p>
<h1 id="ii-computation-and-computability"><span class="caps">II</span>. Computation and Computability</h1>
<p><em><span class="dquo">“</span>As programmers we work with languages and machines that are designed to fit our mental models of the world, and we expect them to come equipped with features that make it easy to translate our ideas into implementations. These human-centered designs are motivated by convenience rather than necessity”</em> - page 182</p>
<p><em><span class="dquo">“</span>[…] hard theoretical constraints: certain problems just can’t be solved by any computer, no matter how fast and efficient it is.”</em> - page 182</p>
<h2 id="programming-with-nothing">Programming with Nothing</h2>
<p>Chruch numerals:</p>
<p><em><span class="dquo">“</span>Each number corresponds to a unique way of repeating an action: the number one corresponds to just performing the action; the number two corresponds to performing it and then performing it again; and so on. The number zero, unsurprisingly, corresponds to not performing the action at all.”</em> - page 189</p>
<p><em><span class="dquo">“</span>[…] Church encoding after Alonzo Church, the inventor of the lambda calculus”</em> - page 190</p>
<p><em><span class="dquo">“</span>[Church numeral to integer] conversion:</em></p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">to_integer</span><span class="p">(</span><span class="nb">proc</span><span class="p">)</span>
    <span class="nb">proc</span><span class="o">[-&gt;</span> <span class="n">n</span> <span class="p">{</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">}</span><span class="o">][</span><span class="mi">0</span><span class="o">]</span>
<span class="k">end</span>
</code></pre></div>
<p><em>This method takes a proc that represents a number and calls it with another proc (which just increments its argument) and the native Ruby number 0.</em>” - page 191</p>
<p>Church to boolean:</p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">to_boolean</span><span class="p">(</span><span class="nb">proc</span><span class="p">)</span>
    <span class="nb">proc</span><span class="o">[</span><span class="kp">true</span><span class="o">][</span><span class="kp">false</span><span class="o">]</span>
<span class="k">end</span>
</code></pre></div>
<p><em><span class="dquo">“</span>This works by taking a proc that represents a Boolean and calling it with <code>true</code> as its first argument and <code>false</code> as its second. <code>TRUE</code> just returns its first argument, so <code>to_boolean(TRUE)</code> will return <code>true</code>, and likewise for <code>FALSE</code> […]”</em> - 193</p>
<p><em><span class="dquo">“</span>In languages like Ruby, the <code>if</code>-<code>else</code> statement is nonstrict (or </em><em>lazy</em><em>): we give it a condition and two blocks, and it evaluates the condition to decide which of the two blocks to evaluate and return — it never evaluates both.”</em> - page 200</p>
<p><em><span class="dquo">“</span>Ruby […] evaluates both arguments before</em> <code>IF</code> <em>gets a chance to decide which one to return.”</em> - page 200</p>
<p><em><span class="dquo">“</span>we can easily implement lists that calculate their contents on the fly, also known as </em><em>streams</em><em>. In fact, there’s no reason why streams even need to be finite, because the calculation only has to generate the list contents as they’re consumed”</em> - page 215</p>
<p><em><span class="dquo">“</span>defining a data structure in terms of itself might seem weird and unusual; in this setting, they’re exactly the same thing, and the Z combinator makes both completely legitimate.”</em> - page 216</p>
<p><em><span class="dquo">“</span>Function calls are the only thing that actually </em><em>happens</em><em> when a lambda calculus program is evaluated”</em> - page 225</p>
<p><em><span class="dquo">“</span>function calls are the only kind of syntax that can be reduced.”</em> - page 225</p>
<p><em><span class="dquo">“</span>You might protest that</em> <code>3 - 5 = 0</code> <em>isn’t called “subtraction” where you come from, and you’d be right: the technical name for this operation is  “monus”, because the nonnegative integers under addition form a commutative monoid instead of a proper abelian group.”</em> - page 229</p>
<h2 id="universality-is-everywhere">Universality Is Everywhere</h2>
<p><em><span class="dquo">“</span>Even though any individual Turing machine has a hardcoded rulebook, the universal Turing machine demonstrates that it’s possible to design a device that can adapt to arbitrary tasks by reading instructions from a tape. These instructions are effectively a piece of software that controls the operation of the machine’s hardware, just like in the general-purpose programmable computers we use every day.”</em> - page 231</p>
<p><em><span class="dquo">“</span>The term Turing complete is often used to describe a system or programming language that can simulate any Turing machine.”</em></p>
<p><em><span class="dquo">“</span>a Turing machine can act as an interpreter for the lambda calculus by storing a representation of a lambda calculus expression on the tape and repeatedly updating it according to a set of reduction rules”</em> - page 234</p>
<p><em><span class="dquo">“</span>Since every Turing machine can be simulated by a lambda calculus program, and every lambda calculus program can be simulated by a Turing machine, the two systems are exactly equivalent in power.”</em> - page 234</p>
<h3 id="partial-recursive-functions">Partial Recursive Functions</h3>
<p><em><span class="dquo">“</span>partial recursive functions are programs that are constructed from four fundamental building blocks in different combinations.</em></p>
<p><em>[…]</em></p>
<p><em>The first two building blocks are called </em><em>zero</em><em> and </em><em>increment</em>**</p>
<p><em>[…]</em></p>
<p><em>third building block, </em><em>recurse</em><em> […]</em></p>
<p><em><strong>recurse</strong> is just a template for defining a certain kind of recursive function.</em></p>
<p><em>The programs that we can assemble out of </em><em>zero</em><em>, </em><em>increment</em><em>, and </em><em>recurse</em><em> are called the </em><em>primitive</em><em> recursive functions.</em></p>
<p><em>All primitive recursive functions are </em><em>total</em><em>: regardless of their inputs, they always halt and return an answer. This is because </em><em>recurse</em><em> is the only legitimate way to define a recursive method, and </em><em>recurse</em><em> always halts: each recursive call makes the last argument closer to zero, and when it inevitably reaches zero, the recursion will stop.</em></p>
<p><em>However, we can’t simulate the full execution of an arbitrary Turing machine with primitive recursive functions, because some Turing machines loop forever, so primitive recursive functions aren’t universal.</em></p>
<p><em>To get a truly universal system we have to add a fourth fundamental operation, </em><em>minimize</em><em>:</em></p>
<p><em><strong>minimize</strong> takes a block and calls it repeatedly with a single numeric argument. For the first call, it provides 0 as the argument, then 1, then 2, and keeps calling the block with larger and larger numbers until it returns zero.</em></p>
<p><em>By adding </em><em>minimize</em><em> to </em><em>zero</em><em>, </em><em>increment</em><em>, and </em><em>recurse</em><em>, we can build many more functions—all the </em><em>partial</em><em> recursive functions—including ones that don’t always halt.</em></p>
<p><em>With </em><em>minimize</em><em>, it’s possible to fully simulate a Turing machine by repeatedly calling the primitive recursive function that performs a single simulation step. The simulation will continue until the machine halts - and if that never happens, it’ll run forever.</em> - pages 235 - 238</p>
<h3 id="ski-combinator-calculus"><span class="caps">SKI</span> Combinator Calculus</h3>
<p><em><span class="dquo">“</span>The <span class="caps">SKI</span> calculus is even simpler, with only two kinds of expression - calls and alphabetic </em><em>symbols</em><em> - and much easier rules. All of its power comes from the three special symbols <code>S</code>, <code>K</code>, and <code>I</code> (called </em><em>combinators</em><em>), each of which has its own reduction rule:</em></p>
<ul>
<li><em>Reduce <code>S[a][b][c]</code> to <code>a[c][b[c]]</code>, where <code>a</code>, <code>b</code>, and <code>c</code> can be any <span class="caps">SKI</span> calculus expressions.</em></li>
<li><em>Reduce <code>K[a][b]</code> to <code>a</code>.</em></li>
<li><em>Reduce <code>I[a]</code> to <code>a</code>.</em></li>
</ul>
<p>page 239</p>
<p><em><span class="dquo">“</span>The <span class="caps">SKI</span> calculus can produce surprisingly complex behavior with its three simple rules—so complex, in fact, that it turns out to be universal.”</em> - page 243</p>
<p><em><span class="dquo">“</span>Although the <span class="caps">SKI</span> calculus has three combinators, the <code>I</code> combinator is actually redundant. There are many expressions containing only <code>S</code> and <code>K</code> that do the same thing as <code>I</code></em></p>
<p>[…]</p>
<p><em><code>S[K][K]</code> has the same behavior as <code>I</code>, and in fact, that’s true for any <span class="caps">SKI</span> expression of the form <code>S[K][whatever]</code>. The <code>I</code> combinator is syntactic sugar that we can live without; just the two combinators <code>S</code> and <code>K</code> are enough for universality.”</em> - pages 245-246</p>
<h3 id="iota">Iota</h3>
<p><em><span class="dquo">“</span>iota (<code>ɩ</code>) is an extra combinator that can be added to the <span class="caps">SKI</span> calculus. Here is its reduction rule: Reduce <code>ɩ[a]</code> to <code>a[S][K]</code>.”</em> - page 246</p>
<p><em><span class="dquo">“</span>[…] a language called Iota whose programs </em><em>only</em><em> use the <code>ɩ</code> combinator. Although it only has one combinator, Iota is a universal language</em>” - page 246</p>
<p><em><span class="dquo">“</span>We can convert an <span class="caps">SKI</span> expression to Iota by applying these substitution rules:</em></p>
<ul>
<li><em>Replace <code>S</code> with <code>ɩ[ɩ[ɩ[ɩ[ɩ]]]]</code>.</em></li>
<li><em>Replace <code>K</code> with <code>ɩ[ɩ[ɩ[ɩ]]]</code>.</em></li>
<li><em>Replace <code>I</code> with <code>ɩ[ɩ]</code>.</em></li>
</ul>
<p>page 246</p>
<h3 id="tag-systems">Tag Systems</h3>
<p><em><span class="dquo">“</span>a tag system operates on a string by repeatedly adding new characters to the end of the string and removing them from the beginning.”</em> - page 248</p>
<p><em><span class="dquo">“</span>A tag system’s description has two parts: first, a collection of rules, where each rule specifies some characters to append to the string when a particular character appears at the beginning […] and second, a number, called the deletion number, which specifies how many characters to delete from the beginning of the string after a rule has been followed.”</em> - page 249</p>
<p><em><span class="dquo">“</span>Having a deletion number greater than 1 is essential for making this tag system work. Because every </em><em>second</em><em> character triggers a rule, we can influence the system’s behavior by arranging for certain characters to appear (or not appear) in these trigger positions.”</em> - page 254</p>
<p><em><span class="dquo">“</span>Cyclic tag systems are extremely limited - they have inflexible rules, only two characters, and the lowest possible deletion number - but surprisingly, it’s still possible to use them to simulate any tag system.”</em> - page 260</p>
<h2 id="impossible-programs">Impossible Programs</h2>
<p><em><span class="dquo">“</span>The practical purpose of a computing machine is to perform algorithms. An algorithm is a list of instructions describing some process for turning an input value into an output value, as long as those instructions fulfill certain criteria:</em></p>
<p>Finiteness:</p>
<p><em>There are a finite number of instructions.</em></p>
<p>Simplicity:</p>
<p><em>Each instruction is simple enough that it can be performed by a person with a pencil and paper without using any ingenuity.</em></p>
<p>Termination:</p>
<p><em>A person following the instructions will finish within a finite number of steps for any input.</em></p>
<p>Correctness:</p>
<p><em>A person following the instructions will produce the right answer for any input.</em></p>
<p>page 274</p>
<p><em><span class="dquo">“</span>can any algorithm be turned into instructions suitable for execution by a machine?”</em> - page 276</p>
<p><em><span class="dquo">“</span>there’s a real difference between the abstract, intuitive idea of an algorithm and the concrete, logical implementation of that algorithm within a computational system. Could there ever be an algorithm so large, complex, and unusual that its essence can’t be captured by an unthinking mechanical process?”</em> - page 276</p>
<p><em><span class="dquo">“</span>the question is philosophical rather than scientific”</em> - page 276</p>
<p><em><span class="dquo">“</span>The idea that any algorithm can be performed by a machine - specifically a deterministic Turing machine - is called the </em><em>Church–Turing thesis</em><em>, and although it’s just a conjecture rather than a proven fact, it has enough evidence in its favor to be generally accepted as true.</em>” - page 277</p>
<h3 id="code-is-data">Code Is Data</h3>
<p><em><span class="dquo">“</span>programs can be represented as data so that they can be used as input to other programs; it’s the unification of code and data that makes software possible in the first place.”</em> - page 279</p>
<h3 id="universal-systems-can-loop-forever">Universal Systems Can Loop Forever</h3>
<p><em><span class="dquo">“</span>any system that’s powerful enough to be universal will inevitably allow us to construct computations that loop forever without halting.”</em> - page 281</p>
<p><em><span class="dquo">“</span>So why must every universal system bring nontermination along for the ride?”</em> - page 283</p>
<p><em><span class="dquo">“</span>it’s impossible to remove features (e.g., <code>while</code> loops) from a programming language in a way that prevents us from writing nonhalting programs while keeping the language powerful enough to be universal.”</em> - page 287</p>
<p><em><span class="dquo">“</span>Languages that have been carefully designed to ensure that their programs must always halt are called </em><em>total programming languages</em><em>, as opposed to the more conventional </em><em>partial programming languages</em><em> whose programs sometimes halt with an answer and sometimes don’t. Total programming languages are still very powerful and capable of expressing many useful computations, but one thing they can’t do is interpret themselves.”</em> - page 287</p>
<p><em><span class="dquo">“</span>a fundamental mathematical result called </em><em>Kleene’s second recursion theorem</em><em>, which guarantees that any program can be converted into an equivalent one that is able to calculate its own source code.”</em> - page 288</p>
<h3 id="decidability">Decidability</h3>
<p><em><span class="dquo">“</span>A decision problem is any question with a yes or no answer”</em></p>
<p><em><span class="dquo">“</span>A decision problem is </em><em>decidable</em><em> (or </em><em>computable</em><em>) if there’s an algorithm that’s guaranteed to solve it in a finite amount of time for any possible input. The Church-Turing thesis claims that every algorithm can be performed by a Turing machine, so for a problem to be decidable, we have to be able to design a Turing machine that always produces the correct answer and always halts if we let it run for long enough.”</em> - page 293</p>
<p><em><span class="dquo">“</span>There are many decision problems - </em><em>infinitely</em><em> many - and it turns out that a lot of them are undecidable: there is no guaranteed-to-halt algorithm for solving them. Each of these problems is undecidable not because we just haven’t found the right algorithm for it yet, but because the problem itself is fundamentally impossible to solve for some inputs, and we can even prove that no suitable algorithm will ever be found.”</em> - page 294</p>
<h3 id="the-halting-problem">The Halting Problem</h3>
<p><em><span class="dquo">“</span>the </em><em>halting problem</em><em>, is the task of deciding whether the execution of a particular Turing machine with a particular initial tape will ever halt.”</em> - page 295</p>
<p><em><span class="dquo">“</span>This is </em><em>Rice’s theorem</em><em>: any nontrivial property of program behavior is undecidable, because the halting problem can always be reduced to the problem of deciding whether that property is true; if we could invent an algorithm for deciding that property, we’d be able to use it to build another algorithm that decides the halting problem, and that’s impossible.”</em> - page 304</p>
<p><em><span class="dquo">“</span>Any system with enough power to be self-referential can’t correctly answer every question about itself.”</em> - page 308</p>
<p><em><span class="dquo">“</span>every pushdown automaton has an equivalent context-free grammar and vice versa; any <span class="caps">CFG</span> can be rewritten in Chomsky normal form; and any <span class="caps">CFG</span> in that form must take exactly 2n − 1 steps to generate a string of length n.”</em> - page 312</p>
<h2 id="programming-in-toyland">Programming in Toyland</h2>
<h3 id="abstract-interpretation">Abstract Interpretation</h3>
<p><em><span class="dquo">“</span>The main idea of abstract interpretation is to use an </em><em>abstraction</em><em>, a model of the real problem that discards enough detail to make it manageable - perhaps by making it smaller, simpler, or by eliminating unknowns - but that also retains enough detail to make its solution relevant to the original problem.”</em> - page 315</p>
<p><em><span class="dquo">“</span>A lot of the time, it’s fine for a result to be imprecise, but for an abstraction to be useful, it’s important that this imprecision is </em><em>safe</em><em>. Safety means that the abstraction always tells the truth: the result of an abstract computation must agree with the result of its concrete counterpart. If not, the abstraction is giving us unreliable information and is probably worse than useless.”</em> - page 321</p>
<h3 id="static-semantics">Static Semantics</h3>
<p><em><span class="dquo">“</span>[…] </em><em>dynamic semantics</em><em> of programming languages, a way of specifying the meaning of code when it’s executed; a language’s </em><em>static semantics</em><em> tells us about properties of programs that we can investigate without executing them. The classic example of static semantics is a </em><em>type system</em><em>”</em> - page 327</p>
<p><em><span class="dquo">“</span>From the perspective of someone designing the static semantics, it’s also more difficult to handle a language where variables can change their types.”</em> - page 334</p>
<p><em><span class="dquo">“</span>Fundamentally, there is a tension between the restrictiveness of a type system and the expressiveness of the programs we can write within it.”</em> - page 334</p>
<p><em><span class="dquo">“</span>A good type system finds an acceptable compromise between restrictiveness and expressiveness, ruling out enough problems to be worthwhile without getting in the way, while being simple enough for programmers to understand.”</em> - page 334</p>
<p><em><span class="dquo">“</span>Any information we get from the type system has to be taken with a pinch of salt, and we have to pay attention to its limitations when deciding how much faith to put in it. A successful execution of a program’s static semantics doesn’t mean “this program will definitely work,” only “this program definitely won’t fail in a particular way” It would be great to have an automated system that can tell us that a program is free of any conceivable kind of bug or error, but as we saw […], the universe just isn’t that convenient.”</em> - page 338</p>
<p><em><span class="dquo">“</span>Formally, abstract interpretation is a mathematical technique where different semantics for the same language are connected together by functions that convert collections of concrete values into abstract ones and vice versa, allowing the results and properties of abstract programs to be understood in terms of concrete ones.”</em> - page 338</p>
<p><em><span class="dquo">“</span>Java has a </em><em>type and effect system</em><em> that tracks not only the types of methods’ arguments and return values but also which </em><em>checked exceptions</em><em> can be thrown by the body of the method (throwing an exception is an </em><em>effect</em><em>), which is used to ensure that all possible exceptions are either handled or explicitly propagated.”</em> - page 339</p>
<h1 id="afterword">Afterword</h1>
<p><em><span class="dquo">“</span>Every computer program is a mathematical object. Syntactically a program is just a large number; semantically it can represent a mathematical function, or a hierarchical structure which can be manipulated by formal reduction rules. This means that many techniques and results from mathematics, like Kleene’s recursion theorem or Gödel’s incompleteness theorem, can equally be applied to programs.”</em> - page 341</p>
<p><em><span class="dquo">“</span>Computation, which we initially described as just “what a computer does”, has turned out to be something of a force of nature. It’s tempting to think of computation as a sophisticated human invention that can only be performed by specially-designed systems with many complicated parts, but it also shows up in systems that don’t seem complex enough to support it. So computation isn’t a sterile, artificial process that only happens inside a microprocessor, but rather a pervasive phenomenon that crops up in many different places and in many different ways.”</em> - page 341</p>
<p><em><span class="dquo">“</span>Computation is not all-or-nothing. Different machines have different amounts of computational power, giving us a continuum of usefulness: DFAs and NFAs have limited capabilities, DPDAs are more powerful, NPDAs more powerful still, and Turing machines are the most powerful we know of.”</em> - page 341</p>
            <!--             <div>
            <span class="author_blurb"><a href=""><span class="author_name">Lukas Woodtli</span></a> -
                </span><br />
</div>
 -->
            
            
            <hr/>
            <aside>
            <nav>
            <ul class="articles-timeline">
                <li class="previous-article">« <a href="./statements_and_expressions.html" title="Previous: Statements and Expressions">Statements and Expressions</a></li>
                <li class="next-article"><a href="./unix_directory_structure.html" title="Next: Unix Directory Structure">Unix Directory Structure</a> »</li>
            </ul>
            </nav>
            </aside>
        </div>
        <section>
        <div class="span2" style="float:right;font-size:0.9em;">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2016-09-12T21:50:33+02:00">Sep 12, 2016</time>

<h4>Last Updated</h4>
<time datetime="2022-04-10T22:19:46+02:00">Apr 10, 2022</time>

            <h4>Category</h4>
            <a class="category-link" href="./categories.html#programming-ref">Programming</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="./tags#computer_science-ref">Computer Science
                    <span>25</span>
</a></li>
            </ul>
<h4>Contact</h4>
    <a href="https://www.linkedin.com/in/lukaswoodtli" title="My LinkedIn Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-linkedin sidebar-social-links"></i></a>
    <a href="https://github.com/LukasWoodtli" title="My github Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-github sidebar-social-links"></i></a>
    <a href="https://stackoverflow.com/cv/lukaswoodtli" title="My stack-overflow Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-stack-overflow sidebar-social-links"></i></a>
    <a href="https://www.xing.com/profile/Lukas_Woodtli" title="My XING Profile" class="sidebar-social-links" target="_blank">
    <i class="fa fa-xing sidebar-social-links"></i></a>
    <a href="/pages/contact.html" title="My email Address" class="sidebar-social-links" target="_blank">
    <i class="fa fa-envelope sidebar-social-links"></i></a>
        </div>
        </section>
</div>
</article>
                </div>
                <div class="span1"></div>
            </div>
        </div>
        <div id="push"></div>
    </div>
<footer>
<div id="footer">
    <ul class="footer-content">
        <li class="elegant-power">Powered by <a href="http://getpelican.com/" title="Pelican Home Page">Pelican</a>. Theme: <a href="https://github.com/Pelican-Elegant/elegant/" title="Theme Elegant Home Page">Elegant</a></li>
    </ul>
</div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    
    </body>
    <!-- Theme: Elegant built for Pelican
    License : MIT -->
</html>